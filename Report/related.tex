\section{Related Work}

Ideas around evolutionary computation began emerging in 1950s. Several researchers, independently from each-other, created algorithms which were inspired by natural Darwinian principles, these include Holland's Genetic Algorithms, Schwefel's and Rechenberg's Evolution Strategies and Fogel's Evolutionary Programming. These pioneering algorithms shared the concepts of populations, individuals, offspring and fitness and ,compared to natural systems, they were quite simplistic, lacking gender, maturation processes, migration, etc~\cite{dejong2009EC}.

Research has shown that no single algorithm can perform better than all other algorithms on average. This has been referred to as the `no-free-lunch' and current solutions instead aim at finding better solutions to specific problems by exploiting inherent biases in the problem. This has led to the desire to classify different algorithms in order to decide which algorithms should be used in which situations, a problem which is not trivial~\cite{dejong2009EC}.

\subsection{Recent Research}

Recent research has focused, among others, on parallelism, multi-population models, multi-objective optimization, dynamic environments and evolving executable code. Parallelism can easily be exploited in EC because of it's inherently parallel nature, e.g each individual in a population can be evaluated, mutated and crossed-over independently. Multi-core CPUs, massively parallel GPUs, clusters and networks can be used to achieve this. Multi-population models mimic the way species depend on each other in nature. Examples of this include host-parasite and predator-prey relationships where the the individual's fitness is connected to the fitness of another individual. Multi-objective optimization aims to solve problems where conflicting interests exist, a good example would be optimizing for power and fuel-consumption simultaneously. In such problems the optimization algorithm has to keep two or more interests in mind simultaneously and find intersections points which offer the best trade-offs between them. Dynamic environments include things like the stock markets and traffic systems. Traditional EAs perform badly in these situations but they can perform well when slightly modified to fit the task. Evolving executable code, as in Genetic Programming and Evolutionary Programming, is a hard problem with very interesting potential applications. Most often low-level code such as assembly, lisp or generic rules are evolved~\cite{dejong2009EC}.

\subsection{Emerging Evolutionary Algorithms}

\paragraph{Variants of Differential Evolution}

Differential evolution (DE) was conceived in 1995 by Storn and Price~\cite{storn1995differential} and soon gained wide acceptance as one of the best algorithms in continuous optimization~\cite{price1997differential}. This spawned many new papers describing variations and hybrids of the algorithm~\cite{5601760}, such as self-adaptive DE (SaDE)~\cite{qin2009differential}, opposition-based DE (ODE)~\cite{rahnamayan2008opposition} and DE with global and local neighborhoods (DEGL)~\cite{rahnamayan2008opposition}.

DE is very easy to implement and has been shown to outperform most other algorithms consistently, it has also been shown that it in general performs better than PSO~\cite{das2009differential, vesterstrom2004comparative}. DE uses very few parameters and the effects of altering these parameters have been well studied~\cite{5601760}. DE comes in a total of 10 different varieties based on which mutation and cross-over operators are used~\cite{price2006differential}. Eight of these schemes have been tested and compared, showing that the version called DE/best/1/bin (which utilizes the best current individual in the cross-over process instead of random individuals) generally yields the best results~\cite{mezura2006comparative}.~\cite{gamperle2002parameter} measured the performance of different combinations of parameters, producing general recommendations for DE.

The desire to find optimal parameters have led to the use of self-adjusting DE algorithms. Examples include the use of fuzzy systems to control the parameters~\cite{liu2005fuzzy} and the SaDE algorithm~\cite{qin2009differential}.

\paragraph{Modified Particle Swarm Optimization}

Particle swarm optimization (PSO) is the most widely used swarm intelligence (SI) algorithm to date. Many modified versions of PSO have been proposed, among others quantum-behaved PSO (QPSO), bare-bones PSO (BBPSO), chaotic PSO, fuzzy PSO, PSOT-VAC and opposition-based PSO. PSO has also been hybridized with other evolutionary algorithm, for instance: genetic algorithms (GA), artificial immune systems (AIS), tabu search (TS), ant colony optimization (ACO), simulated annealing (SA), differential evolution (DE), bio-geography based optimization (BBO) and harmonic search (HS)~\cite{zhang2015comprehensive}.

Wang et al.~\cite{dang2012selection} have compared the performance of different PSO-parameters and proposed a set of criteria for improving the performance of PSO. Fuzzy logic controllers (FLC) have been used to continuously optimize the PSO-parameters by Kumar and Chaturvedi~\cite{kumar2011tuning}. Zhang et al. found a simple way to use control theory in order to find good parameters~\cite{zhang2011simple}. Yang proposed modified velocity PSO (MVPSO) in which particles learn the best parameters from the other particles~\cite{yang2011particle}.


\paragraph{Improvement of Estimation of Distribution Algorithms}

Estimation of distribution algorithms (EDA) use probabilistic models to solve complex optimization problems. They have been successful at many engineering problems which at which other algorithms have failed, for instance: military antenna design, protein structure prediction, clustering of genes, chemotherapy optimization, portfolio management, etc~\cite{Hauschild2011111}.

Several techniques have been proposed to make EDA more efficient. Parallelization of fitness evaluation and model building has proven effective~\cite{sastry2007towards}. Local optimization techniques such as deterministic hill climbing (DHC) has been shown to make EDA faster~\cite{hart1994adaptive}.

\subsection{Evolutionary Algorithms and Machine Learning}

Evolutionary algorithms (EC) and machine learning (ML) are two growing and promising field in computer science and many attempts have therefore been made to combine the two. ML has been used to improve EC optimization algorithms with so called MLEC-algorithms where various techniques from AI and ML, such as artificial neural networks (ANN), cluster analysis (CA), support vector machines (SVM), etc. help EC algorithms to learn important features of the search space~\cite{6052374}.

The opposite use case has also been proposed, using EC to improve ML techniques. An example of this is using DE to optimize feed-forward neural networks (FFNN). Here DE seems to perform similarly to traditional gradient based techniques~\cite{ilonen2003differential}. Hajare and Bawane showed that using PSO to initialize weights and biases in a neural network before training yields better results than using random weights and help avoid local minima which back-propagation (BP) algorithms often get stuck in~\cite{hajare2015feed}. Larra{\~n}aga and Lozano~\cite{larranaga2001estimation} tested various EC algorithms (GA, EDA and ES) agains BP and concluded that EC is a competitive alternative to traditional approaches.

\subsection{Contributions}

EC is a an interesting alternative to traditional approaches in machine learning and continuous optimization and while algorithms such as DE, PSO, etc. have been compared on mathematical benchmarks before~\cite{vesterstrom2004comparative, price1997differential}, the application of EC to machine learning has not been studied with as much detail. My primary contribution to the field will be to find what algorithms work best for different ML problems and based on this propose ML-specific improvements.
