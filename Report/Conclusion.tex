\section{Conclusions}

The thesis has a two-fold contribution. Firstly, three evolutionary algorithm were benchmarked on mathematical optimization problems and machine learning problems involving feed-forward artificial neural networks. The algorithms in question were Differential Evolution (DE), Particle Swarm Optimization (PSO) and Estimation of Distribution Algorithm (EDA). The second contribution was the creation of a novel evolutionary algorithm (DEDA), inspired by the former algorithms, with the intention to improve performance in machine learning. The new algorithm was also benchmarked on the same tasks as the other algorithms and has been compared to them.

The results of the benchmarks show that PSO and the proposed algorithm DEDA performed best on the mathematical benchmark, while DEDA and EDA worked best for machine learning problems on standard training data sets. PSO produces the best results for neural network game controllers.

The proposed algorithm is an Estimation of Distribution Algorithm which has been modified to include features common in Differential Evolution. The main principle is that the population improves by probabilistic sampling and differential mutation at the same time.

The algorithm has been shown to exhibit good performance on the benchmarks overall and even outperformed the other algorithms on many of the tasks. It proved especially useful when optimizing neural networks for function approximation, classification and clustering. It is also interesting to note that in cases where DE and EDA would perform worse than PSO, DEDA (combining features from the two) was able to perform better than PSO.

\subsection{Future Work}

Since there exit many variations of the three popular algorithms presented in this thesis, it would be interesting to compare different varieties of algorithms which performed best on the machine learning problem sets in order to find specific optimizations which work well with machine learning.

Another interesting research area is trying different ways of accomplishing the hybridization of principles from Estimation of Distribution Algorithms and Differential Evolution. One might, for instance, investigate whether the order in which model building and mutation are applied affects the algorithms performance.
